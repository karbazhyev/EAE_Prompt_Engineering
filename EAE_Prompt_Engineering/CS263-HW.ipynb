{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAW1pKvx5PTz"
   },
   "source": [
    "# CS 263 HW Notebook\n",
    "\n",
    "This notebook comprises of python scripts to extract chatgpt output and instructions for checking the format of your files for the submission of the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4CBD9F0MLU9"
   },
   "source": [
    "## Extract ChatGPT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def argument_extractor(chatgpt_output, argument_roles=None):\n",
    "  #######\n",
    "  # TODO: Write a function to extract arguments corresponding to the \n",
    "  # argument roles from the chatgpt_output\n",
    "  # If argument roles are provided, this will extract only those arguments\n",
    "  # Else it will extract all possible arguments from the output\n",
    "  #######\n",
    "    def delist(value):\n",
    "        while isinstance(value, list) and len(value) == 1:\n",
    "            value = value[0]\n",
    "        if value == []:\n",
    "            value = \"\"\n",
    "        return value\n",
    "\n",
    "\n",
    "    chatgpt_output = chatgpt_output.strip(\"\\\"\")\n",
    "    chatgpt_output = \"{\" + chatgpt_output + \"}\"\n",
    "    argument_dict = literal_eval(chatgpt_output)\n",
    "    new_argument_dict = {k: delist(v) for k, v in argument_dict['arguments'].items()}\n",
    "    return new_argument_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PrgnulpMPCP"
   },
   "source": [
    "## File-check for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "wViu0qpq5LHp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "EVENT_NAMES = [\"infect\", \"spread\", \"symptom\", \"cure\", \"prevent\", \"control\", \"death\"]\n",
    "ONTOLOGY_FIELD_NAMES = {\"event_name\": str, \"argument_role\": str, \"role_description\": str, \"example_sentence\": str}\n",
    "DATA_ANNOTATION_FIELD_NAMES = {\"input_text\": str, \"event_name\": str, \"event_trigger\": str, \"arguments\": dict}\n",
    "PREDICTION_FIELD_NAMES = {\"input_text\": str, \"prompt\": str, \"output_text\": str, \"extracted_arguments\": dict}\n",
    "BREAKGPT_FIELD_NAMES = {\"input_text\": str, \"event_name\": str, \"event_trigger\": str, \"prompt\": str, \"output_text\": str, \"extracted_arguments\": dict, \"expected_arguments\": dict}\n",
    "\n",
    "def ontology_check(filename):\n",
    "  data = None\n",
    "  with open(filename, 'r') as f:\n",
    "    try:\n",
    "      data = json.load(f)\n",
    "    except:\n",
    "      print (\"ERROR: File is not a json file. Use json.dump to create your file\")\n",
    "      return\n",
    "  \n",
    "  for i, dt in enumerate(data):\n",
    "    for field_name in dt.keys():\n",
    "      if field_name not in ONTOLOGY_FIELD_NAMES:\n",
    "        print (\"ERROR: Line %d: field name %s is incorrect. It should be within %s\" % (i+1, field_name, str(ONTOLOGY_FIELD_NAMES.keys())))\n",
    "        return\n",
    "\n",
    "    if dt[\"event_name\"] not in EVENT_NAMES:\n",
    "      print (\"ERROR: line %d has unknown event name %s. Please check.\" % (i+1, dt[\"event_name\"]))\n",
    "      return\n",
    "  \n",
    "  print (\"PASSED: The format of the file %s looks correct!\" % filename)\n",
    "  return\n",
    "\n",
    "def json_check(filename, required_field_names, is_logs=0):\n",
    "  data = None\n",
    "  with open(filename, 'r') as f:\n",
    "    try:\n",
    "      data = json.load(f)\n",
    "    except:\n",
    "      print (\"ERROR: File is not a json file. Use json.dump to create your file\")\n",
    "      return\n",
    "    \n",
    "  for i, dt in enumerate(data):\n",
    "    for field_name in dt.keys():\n",
    "      if field_name not in required_field_names.keys():\n",
    "        print (\"ERROR: Line %d: field name %s is incorrect. It should be within %s\" % (i+1, field_name, str(required_field_names.keys())))\n",
    "        return\n",
    "\n",
    "    for var, typ in required_field_names.items():\n",
    "      if not isinstance(dt[var], typ):\n",
    "        print (\"ERROR: Line %d: dt['%s'] is not a %s\" % (i+1, var, str(typ)))\n",
    "        return\n",
    "    \n",
    "    if \"arguments\" in required_field_names and \"input_text\" in required_field_names:\n",
    "      for role, arg in dt[\"arguments\"].items():\n",
    "        if isinstance(arg, str) and arg not in dt[\"input_text\"]:\n",
    "          print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, arg))\n",
    "          return\n",
    "        elif isinstance(arg, list):\n",
    "          for a in arg:\n",
    "            assert isinstance(a, str)\n",
    "            if a not in dt[\"input_text\"]:\n",
    "              print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, a))\n",
    "              return\n",
    "    \n",
    "    if \"expected_arguments\" in required_field_names and \"input_text\" in required_field_names:\n",
    "      for role, arg in dt[\"expected_arguments\"].items():\n",
    "        if isinstance(arg, str) and arg not in dt[\"input_text\"]:\n",
    "          print (\"ERROR: Line %d: expected argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, arg))\n",
    "          return\n",
    "        elif isinstance(arg, list):\n",
    "          for a in arg:\n",
    "            assert isinstance(a, str)\n",
    "            if a not in dt[\"input_text\"]:\n",
    "              print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, a))\n",
    "              return\n",
    "    if \"extracted_arguments\" in required_field_names and \"output_text\" in required_field_names and not is_logs:\n",
    "      if argument_extractor(dt[\"output_text\"]) != dt[\"extracted_arguments\"]:\n",
    "        print (\"ERROR: Line %d: extracted arguments is inconsistent with chatgpt output based on script\" % (i+1))\n",
    "        return\n",
    "\n",
    "  print (\"PASSED: The format of the file %s looks correct!\" % filename)\n",
    "  return\n",
    "\n",
    "def check_all_file_format():\n",
    "  ontology_check(\"ontology.json\")\n",
    "  json_check(\"in_context-annotated.json\", DATA_ANNOTATION_FIELD_NAMES)\n",
    "  json_check(\"eval_data-annotated.json\", DATA_ANNOTATION_FIELD_NAMES)\n",
    "  json_check(\"logs.json\", PREDICTION_FIELD_NAMES, is_logs=1)\n",
    "  json_check(\"pred.json\", PREDICTION_FIELD_NAMES)\n",
    "  json_check(\"break-gpt.json\", BREAKGPT_FIELD_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "pzkg0WjUgaPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: The format of the file ontology.json looks correct!\n",
      "PASSED: The format of the file in_context-annotated.json looks correct!\n",
      "PASSED: The format of the file eval_data-annotated.json looks correct!\n",
      "PASSED: The format of the file logs.json looks correct!\n",
      "PASSED: The format of the file pred.json looks correct!\n",
      "PASSED: The format of the file break-gpt.json looks correct!\n"
     ]
    }
   ],
   "source": [
    "check_all_file_format()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1BQr3j_qUQYqyXK9Kr9lg_lnnxSzmQcyv",
     "timestamp": 1684026798407
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
